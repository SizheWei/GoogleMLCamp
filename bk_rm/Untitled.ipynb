{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "credit https://blog.csdn.net/weixin_42135399/article/details/90178673"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    " \n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self,in_ch,out_ch):\n",
    "        super(DoubleConv,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "                nn.Conv2d(in_ch,out_ch,3,padding=1),#in_ch、out_ch是通道数\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.ReLU(inplace = True),\n",
    "                nn.Conv2d(out_ch,out_ch,3,padding=1),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.ReLU(inplace = True)  \n",
    "            )\n",
    "    def forward(self,x):\n",
    "        return self.conv(x)\n",
    " \n",
    " \n",
    "class UNet(nn.Module):\n",
    "    def __init__(self,in_ch,out_ch):\n",
    "        super(UNet,self).__init__()\n",
    "        self.conv1 = DoubleConv(in_ch,64)\n",
    "        self.pool1 = nn.MaxPool2d(2)#每次把图像尺寸缩小一半\n",
    "        self.conv2 = DoubleConv(64,128)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.conv3 = DoubleConv(128,256)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.conv4 = DoubleConv(256,512)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "        self.conv5 = DoubleConv(512,1024)\n",
    "        #逆卷积\n",
    "        self.up6 = nn.ConvTranspose2d(1024,512,2,stride=2)\n",
    "        self.conv6 = DoubleConv(1024,512)\n",
    "        self.up7 = nn.ConvTranspose2d(512,256,2,stride=2)\n",
    "        self.conv7 = DoubleConv(512,256)\n",
    "        self.up8 = nn.ConvTranspose2d(256,128,2,stride=2)\n",
    "        self.conv8 = DoubleConv(256,128)\n",
    "        self.up9 = nn.ConvTranspose2d(128,64,2,stride=2)\n",
    "        self.conv9 = DoubleConv(128,64)\n",
    "        \n",
    "        self.conv10 = nn.Conv2d(64,out_ch,1)\n",
    "        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        c1 = self.conv1(x)\n",
    "        p1 = self.pool1(c1)\n",
    "        c2 = self.conv2(p1)\n",
    "        p2 = self.pool2(c2)\n",
    "        c3 = self.conv3(p2)\n",
    "        p3 = self.pool3(c3)\n",
    "        c4 = self.conv4(p3)\n",
    "        p4 = self.pool4(c4)\n",
    "        c5 = self.conv5(p4)\n",
    "        up_6 = self.up6(c5)\n",
    "        merge6 = torch.cat([up_6,c4],dim=1)#按维数1（列）拼接,列增加\n",
    "        c6 = self.conv6(merge6)\n",
    "        up_7 = self.up7(c6)\n",
    "        merge7 = torch.cat([up_7,c3],dim=1)\n",
    "        c7 = self.conv7(merge7)\n",
    "        up_8 = self.up8(c7)\n",
    "        merge8 = torch.cat([up_8,c2],dim=1)\n",
    "        c8 = self.conv8(merge8)\n",
    "        up_9 = self.up9(c8)\n",
    "        merge9 = torch.cat([up_9,c1],dim=1)\n",
    "        c9 = self.conv9(merge9)\n",
    "        c10 = self.conv10(c9)\n",
    "        \n",
    "        out = nn.Sigmoid()(c10)#化成(0~1)区间\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import os\n",
    "import PIL.Image as Image\n",
    " \n",
    "#data.Dataset:\n",
    "#所有子类应该override__len__和__getitem__，前者提供了数据集的大小，后者支持整数索引，范围从0到len(self)\n",
    " \n",
    "class LiverDataset(data.Dataset):\n",
    "    #创建LiverDataset类的实例时，就是在调用init初始化\n",
    "#     def __init__(self,root,transform = None,target_transform = None):#root表示图片路径\n",
    "    def __init__(self):\n",
    "#         n = len(os.listdir(root))//2 #os.listdir(path)返回指定路径下的文件和文件夹列表。/是真除法,//对结果取整\n",
    "        \n",
    "#         imgs = []\n",
    "#         for i in range(n):\n",
    "#             img = os.path.join(root,\"%03d.png\"%i)#os.path.join(path1[,path2[,......]]):将多个路径组合后返回\n",
    "#             mask = os.path.join(root,\"%03d_mask.png\"%i)\n",
    "#             imgs.append([img,mask])#append只能有一个参数，加上[]变成一个list\n",
    "        \n",
    "#         self.imgs = imgs\n",
    "#         self.transform = transform\n",
    "#         self.target_transform = target_transform\n",
    "#         data_dir_clip = '/home/szweisjtu/data/aisegmentcom-matting-human-datasets/clip_img/1803151818/clip_00000000'\n",
    "        data_dir_clip = '/home/vivi/sace/Google_ML_Camp/bk_rm/data/clip_img/1803151818/clip_00000000'\n",
    "\n",
    "#         data_dir_mat = '/home/szweisjtu/data/aisegmentcom-matting-human-datasets/matting/1803151818/matting_00000000'\n",
    "        data_dir_mat = '/home/vivi/sace/Google_ML_Camp/bk_rm/data/matting/1803151818/clip_00000000'\n",
    "    \n",
    "        # n = len(os.listdir(data_dir_clip))\n",
    "        clip_imgs = os.listdir(data_dir_clip)\n",
    "        # mat_imgs = os.listdir(data_dir_mat)\n",
    "        imgs = []\n",
    "\n",
    "        for enu_num, img_clip in enumerate(clip_imgs):\n",
    "            img_mat = img_clip[0:-4]+'.png'\n",
    "            img_clip_path = data_dir_clip + '/' + img_clip\n",
    "            img_mat_path = data_dir_mat + '/' + img_mat\n",
    "#             img_clip_r = cv2.imread(img_clip_path)\n",
    "#             img_mat_r = cv2.imread(img_mat_path, cv2.IMREAD_UNCHANGED)\n",
    "#             Alpha = img_mat_r[:,:,3]\n",
    "            imgs.append([img_clip_path,img_mat_path])\n",
    "#             if enu_num==1:\n",
    "#                 break\n",
    "        self.imgs = imgs   \n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        x_path,y_path = self.imgs[index]\n",
    "        img_x = Image.open(x_path)\n",
    "#         img_y = Image.open(y_path)\n",
    "        img_y_ori = cv2.imread(y_path, cv2.IMREAD_UNCHANGED)\n",
    "        img_y = img_y_ori[:,:,3]\n",
    "#         if self.transform is not None:\n",
    "#             img_x = self.transform(img_x)\n",
    "#         if self.target_transform is not None:\n",
    "#             img_y = self.target_transform(img_y)\n",
    "        return img_x,img_y#返回的是图片\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)#400,list[i]有两个元素，[img,mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import os\n",
    "# import cv2\n",
    "# data_dir_clip = '/home/vivi/sace/Google_ML_Camp/bk_rm/data/clip_img/1803151818/clip_00000000/'\n",
    "# data_dir_mat = '/home/vivi/sace/Google_ML_Camp/bk_rm/data/matting/1803151818/clip_00000000'\n",
    "# # n = len(os.listdir(data_dir_clip))\n",
    "# clip_imgs = os.listdir(data_dir_clip)\n",
    "# # mat_imgs = os.listdir(data_dir_mat)\n",
    "# imgs_clip = []\n",
    "\n",
    "# for enu_num, img_clip in enumerate(clip_imgs):\n",
    "#     img_mat = img_clip[0:-4]+'.png'\n",
    "#     img_mat_path = data_dir_mat+'/'+img_mat\n",
    "#     img_mat_r = cv2.imread(img_mat_path, cv2.IMREAD_UNCHANGED)\n",
    "#     Alpha = img_mat_r[:,:,3]\n",
    "#     if enu_num == 0:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_mat_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import transforms as T\n",
    "import argparse #argparse模块的作用是用于解析命令行参数，例如python parseTest.py input.txt --port=8080\n",
    "# import unet\n",
    "from torch import optim\n",
    "# from dataset import LiverDataset\n",
    "from torch.utils.data import DataLoader\n",
    " \n",
    " \n",
    "# 是否使用current cuda device or torch.device('cuda:0')\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    " \n",
    "x_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    # 标准化至[-1,1],规定均值和标准差\n",
    "    T.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])#torchvision.transforms.Normalize(mean, std, inplace=False)\n",
    "])\n",
    "# mask只需要转换为tensor\n",
    "y_transform = T.ToTensor()\n",
    " \n",
    "def train_model(model,criterion,optimizer,dataload,num_epochs=20):\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        dataset_size = len(dataload.dataset)\n",
    "        epoch_loss = 0\n",
    "        step = 0 #minibatch数\n",
    "        for x, y in dataload:# 分100次遍历数据集，每次遍历batch_size=4\n",
    "            optimizer.zero_grad()#每次minibatch都要将梯度(dw,db,...)清零\n",
    "            inputs = x.to(device)\n",
    "            labels = y.to(device)\n",
    "            outputs = model(inputs)#前向传播\n",
    "            loss = criterion(outputs, labels)#计算损失\n",
    "            loss.backward()#梯度下降,计算出梯度\n",
    "            optimizer.step()#更新参数一次：所有的优化器Optimizer都实现了step()方法来对所有的参数进行更新\n",
    "            epoch_loss += loss.item()\n",
    "            step += 1\n",
    "            print(\"%d/%d,train_loss:%0.3f\" % (step, dataset_size // dataload.batch_size, loss.item()))\n",
    "        print(\"epoch %d loss:%0.3f\" % (epoch, epoch_loss))\n",
    "    torch.save(model.state_dict(),'weights_%d.pth' % epoch)# 返回模型的所有内容\n",
    "    return model\n",
    " \n",
    "#训练模型\n",
    "def train():\n",
    "    model = UNet(3,1).to(device)\n",
    "#     batch_size = args.batch_size\n",
    "    batch_size = arg_batch_size\n",
    "\n",
    "    #损失函数\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    #梯度下降\n",
    "    optimizer = optim.Adam(model.parameters())#model.parameters():Returns an iterator over module parameters\n",
    "    #加载数据集\n",
    "#     liver_dataset = LiverDataset(\"data/train\", transform=x_transform, target_transform=y_transform)\n",
    "    liver_dataset = LiverDataset()\n",
    "    dataloader = DataLoader(liver_dataset, batch_size=batch_size, shuffle=True,num_workers=1)\n",
    "    # DataLoader:该接口主要用来将自定义的数据读取接口的输出或者PyTorch已有的数据读取接口的输入按照batch size封装成Tensor\n",
    "    # batch_size：how many samples per minibatch to load，这里为4，数据集大小400，所以一共有100个minibatch\n",
    "    # shuffle:每个epoch将数据打乱，这里epoch=10。一般在训练数据中会采用\n",
    "    # num_workers：表示通过多个进程来导入数据，可以加快数据导入速度 \n",
    "    train_model(model,criterion,optimizer,dataloader)\n",
    " \n",
    "#测试\n",
    "def test():\n",
    "    model = UNet(3,1)\n",
    "    model.load_state_dict(torch.load(args.weight,map_location='cpu'))\n",
    "#     liver_dataset = LiverDataset(\"data/val\", transform=x_transform, target_transform=y_transform)\n",
    "    liver_dataset = LiverDataset()\n",
    "    dataloaders = DataLoader(liver_dataset)#batch_size默认为1\n",
    "    model.eval()\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.ion()\n",
    "    with torch.no_grad():\n",
    "        for x, _ in dataloaders:\n",
    "            y=model(x)\n",
    "            img_y=torch.squeeze(y).numpy()\n",
    "            plt.imshow(img_y)\n",
    "            plt.pause(0.01)\n",
    "        plt.show()\n",
    " \n",
    " \n",
    "# if __name__ == '__main__':\n",
    "#     #参数解析\n",
    "#     parser = argparse.ArgumentParser() #创建一个ArgumentParser对象\n",
    "#     parser.add_argument('action', type=str, help='train or test')#添加参数\n",
    "#     parser.add_argument('--batch_size', type=int, default=4)\n",
    "#     parser.add_argument('--weight', type=str, help='the path of the mode weight file')\n",
    "#     args = parser.parse_args()\n",
    "    \n",
    "#     if args.action == 'train':\n",
    "#         train()\n",
    "#     elif args.action == 'test':\n",
    "#         test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "Caught NameError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/vivi/anaconda3/envs/3dunet/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/vivi/anaconda3/envs/3dunet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/vivi/anaconda3/envs/3dunet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-9-9c6e1657fa5f>\", line 50, in __getitem__\n    img_y_ori = cv2.imread(y_path, cv2.IMREAD_UNCHANGED)\nNameError: name 'cv2' is not defined\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-518f637bff49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0marg_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/vivi/sace/Google_ML_Camp/bk_rm/model'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-0e6299494c36>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# shuffle:每个epoch将数据打乱，这里epoch=10。一般在训练数据中会采用\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# num_workers：表示通过多个进程来导入数据，可以加快数据导入速度\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m#测试\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-0e6299494c36>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, dataload, num_epochs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m#minibatch数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m# 分100次遍历数据集，每次遍历batch_size=4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#每次minibatch都要将梯度(dw,db,...)清零\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/3dunet/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/3dunet/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/3dunet/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: Caught NameError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/vivi/anaconda3/envs/3dunet/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/vivi/anaconda3/envs/3dunet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/vivi/anaconda3/envs/3dunet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-9-9c6e1657fa5f>\", line 50, in __getitem__\n    img_y_ori = cv2.imread(y_path, cv2.IMREAD_UNCHANGED)\nNameError: name 'cv2' is not defined\n"
     ]
    }
   ],
   "source": [
    "arg_batch_size = 4\n",
    "weight = '/home/vivi/sace/Google_ML_Camp/bk_rm/model'\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
