{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self,in_ch,out_ch):\n",
    "        super(DoubleConv,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "                nn.Conv2d(in_ch,out_ch,3,padding=1),#in_ch、out_ch是通道数\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.ReLU(inplace = True),\n",
    "                nn.Conv2d(out_ch,out_ch,3,padding=1),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.ReLU(inplace = True)  \n",
    "            )\n",
    "    def forward(self,x):\n",
    "        return self.conv(x)\n",
    "\n",
    "conv1 = DoubleConv(3,64)\n",
    "pool1 = nn.MaxPool2d(2)\n",
    "conv2 = DoubleConv(64,128)\n",
    "pool2 = nn.MaxPool2d(2)\n",
    "conv3 = DoubleConv(128,256)\n",
    "pool3 = nn.MaxPool2d(2)\n",
    "conv4 = DoubleConv(256,512)\n",
    "pool4 = nn.MaxPool2d(2)\n",
    "conv5 = DoubleConv(512,1024)\n",
    "up6 = nn.ConvTranspose2d(1024,512,2,stride=2)\n",
    "conv6 = DoubleConv(1024,512)\n",
    "up7 = nn.ConvTranspose2d(512,256,2,stride=2)\n",
    "conv7 = DoubleConv(512,256)\n",
    "up8 = nn.ConvTranspose2d(256,128,2,stride=2)\n",
    "conv8 = DoubleConv(256,128)\n",
    "up9 = nn.ConvTranspose2d(128,64,2,stride=2)\n",
    "conv9 = DoubleConv(128,64)\n",
    "out_ch = 1\n",
    "conv10 = nn.Conv2d(64,out_ch,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "liver_dataset = LiverDataset()\n",
    "dataloader = DataLoader(liver_dataset, 4, shuffle=True,num_workers=1)\n",
    "for __num__,(x, y) in enumerate(tqdm(dataloader)):\n",
    "    inputs = x.to(device, dtype = torch.float)\n",
    "    labels = y.to(device, dtype = torch.float)\n",
    "    labels = labels.unsqueeze(1)\n",
    "    c1 = conv1(inputs)\n",
    "    p1 = pool1(c1)\n",
    "    c2 = conv2(p1)\n",
    "    p2 = pool2(c2)\n",
    "    c3 = conv3(p2)\n",
    "    p3 = pool3(c3)\n",
    "    c4 = conv4(p3)\n",
    "    p4 = pool4(c4)\n",
    "    c5 = conv5(p4)\n",
    "    up_6 = up6(c5)\n",
    "    merge6 = torch.cat([up_6,c4],dim=1)#按维数1（列）拼接,列增加\n",
    "    c6 = conv6(merge6)\n",
    "    up_7 = up7(c6)\n",
    "    merge7 = torch.cat([up_7,c3],dim=1)\n",
    "    c7 = conv7(merge7)\n",
    "    up_8 = up8(c7)\n",
    "    merge8 = torch.cat([up_8,c2],dim=1)\n",
    "    c8 = conv8(merge8)\n",
    "    up_9 = up9(c8)\n",
    "    merge9 = torch.cat([up_9,c1],dim=1)\n",
    "    c9 = conv9(merge9)\n",
    "    c10 = conv10(c9)\n",
    "    out = nn.Sigmoid()(c10)#化成(0~1)区间\n",
    "    if __num__ == 0:\n",
    "        break\n",
    "print(c1.shape)\n",
    "print(p1.shape)\n",
    "print(c2.shape)\n",
    "print(p2.shape)\n",
    "print(c3.shape)\n",
    "print(p3.shape)\n",
    "print(c4.shape)\n",
    "print(p4.shape)\n",
    "print(c5.shape)\n",
    "print(up_6.shape)\n",
    "\n",
    "labels[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_clip = './data/aisegmentcom-matting-human-datasets/clip_img/1803151818/clip_00000000'\n",
    "#         data_dir_clip = '/home/vivi/sace/Google_ML_Camp/bk_rm/data/clip_img/1803151818/clip_00000000'\n",
    "\n",
    "data_dir_mat = './data/aisegmentcom-matting-human-datasets/matting/1803151818/matting_00000000'\n",
    "#         data_dir_mat = '/home/vivi/sace/Google_ML_Camp/bk_rm/data/matting/1803151818/clip_00000000'\n",
    "    \n",
    "        # n = len(os.listdir(data_dir_clip))\n",
    "clip_imgs = os.listdir(data_dir_clip)\n",
    "        # mat_imgs = os.listdir(data_dir_mat)\n",
    "imgs = []\n",
    "\n",
    "for enu_num, img_clip in enumerate(clip_imgs):\n",
    "    img_mat = img_clip[0:-4]+'.png'\n",
    "    img_clip_path = data_dir_clip + '/' + img_clip\n",
    "    img_mat_path = data_dir_mat + '/' + img_mat\n",
    "\n",
    "    imgs.append([img_clip_path,img_mat_path])\n",
    "\n",
    "    if enu_num == 0:\n",
    "        break\n",
    "\n",
    "img_y_ori = cv2.imread(img_mat_path, cv2.IMREAD_UNCHANGED)\n",
    "img_y = img_y_ori[:,:,3]\n",
    "img_y = img_y[144:656, 44:556]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = (img_y>1)*1\n",
    "testset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
